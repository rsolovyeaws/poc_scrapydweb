filebeat.inputs:
- type: container
  paths:
    - '/var/lib/docker/containers/*/*.log'
  processors:
    - add_docker_metadata:
        host: "unix:///var/run/docker.sock"
    - decode_json_fields:
        fields: ["message"]
        target: "json"
        overwrite_keys: true

- type: log
  paths:
    - '/logs/scrapyd/demo-1.0-py3.10/quotes_spa/*.log'
    - '/logs/scrapyd/demo-1.0-py3.10/*/*.log'
    - '/logs/scrapyd/**/*.log'
  fields:
    log_type: spider_logs
    spider_project: "demo"
  fields_under_root: true
  multiline:
    pattern: '^[0-9]{4}-[0-9]{2}-[0-9]{2}'
    negate: true
    match: after
  encoding: utf-8
  scan_frequency: 10s
  harvester_buffer_size: 16384

processors:
  - add_host_metadata: ~
  - add_cloud_metadata: ~
  - add_docker_metadata: ~
  - add_fields:
      target: ''
      fields:
        scrapy_logs: true

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  indices:
    - index: "filebeat-%{[agent.version]}-%{+yyyy.MM.dd}"

setup.kibana:
  host: "kibana:5601"

setup.ilm:
  enabled: auto
  rollover_alias: "filebeat"
  pattern: "{now/d}-000001"
  
logging.json: true
logging.metrics.enabled: false
logging.level: debug 