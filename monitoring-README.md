# Мониторинг и логирование для системы скрапинга

Это руководство описывает систему мониторинга и логирования, добавленную в проект скрапинга.

## Компоненты системы

### 1. Сбор и хранение логов (ELK стек)

- **Elasticsearch**: хранение и индексирование логов
- **Kibana**: визуализация и поиск по логам
- **Filebeat**: сбор логов из контейнеров Docker

### 2. Мониторинг метрик

- **Prometheus**: сбор и хранение метрик
- **Grafana**: визуализация метрик
- **cAdvisor**: сбор метрик контейнеров
- **Node Exporter**: сбор метрик хост-системы

### 3. Система оповещений

- **Alertmanager**: управление оповещениями
- **Telegram Alerts**: отправка уведомлений в Telegram

## Доступ к дашбордам

После запуска системы вы можете получить доступ к дашбордам по следующим адресам:

- **Kibana**: http://localhost:5601
- **Grafana**: http://localhost:3000 (логин: admin, пароль: admin)
- **Prometheus**: http://localhost:9090

## Настройка оповещений в Telegram

1. Создайте бота в Telegram через [@BotFather](https://t.me/BotFather)
2. Получите токен бота
3. Создайте группу в Telegram и добавьте в неё бота
4. Узнайте ID чата (можно через @getidsbot)
5. Скопируйте файл `env.template` в `.env` и обновите значения:
   ```bash
   cp env.template .env
   nano .env  # Или любой другой редактор
   ```
6. Добавьте `.env` в `.gitignore`, чтобы не хранить учетные данные в репозитории:
   ```bash
   echo ".env" >> .gitignore
   ```

### Тестирование оповещений

После настройки Telegram-бота и обновления файла `.env` вы можете протестировать систему оповещений:

```bash
# Запустите тестовый скрипт
python test_telegram_alert.py

# Или напрямую, если скрипт исполняемый
./test_telegram_alert.py
```

Если всё настроено правильно, вы должны получить тестовое сообщение в указанном Telegram-чате.

> **Примечание**: Этот скрипт отправляет уведомление только один раз. При последующих запусках он не будет отправлять повторное сообщение. Чтобы отправить ещё одно тестовое сообщение, удалите файл-маркер: `rm .telegram_test_sent`

### Отправка ручных уведомлений

Вы можете отправлять произвольные уведомления с помощью скрипта `send_notification.py`:

```bash
# Отправить простое уведомление
./send_notification.py "Заголовок сообщения" "Текст сообщения"

# Отправить предупреждение
./send_notification.py --severity=warning "Внимание" "Критически важное предупреждение"

# Отправить критическое оповещение
./send_notification.py --severity=critical "Критическая ошибка" "Система недоступна"

# Указать другие параметры
./send_notification.py --alertname="CrawlComplete" --instance="spider-daily" "Парсинг завершен" "Обработано 1000 страниц"
```

Этот инструмент можно использовать в ваших скриптах для отправки уведомлений о важных событиях парсинга.

## Доступные метрики

### Системные метрики

- Загрузка CPU
- Использование памяти
- Дисковое пространство
- Сетевой трафик

### Метрики скрапинга

- Количество активных пауков
- Скорость запросов
- Статусы ответов (200, 404, 503, etc.)
- Ошибки и исключения
- Глубина запросов
- Размеры ответов
- Задержки запросов

## Доступные дашборды

### Grafana

- **Scraper Dashboard**: основной дашборд для мониторинга процесса скрапинга
- **Docker Containers**: мониторинг контейнеров Docker
- **System Overview**: общий мониторинг системы

### Kibana

- Поиск по логам
- Визуализация ошибок
- Анализ трендов

## Настройка алертов

Алерты настроены в файле `prometheus_rules.yml`. Основные алерты:

- **ScrapydInstanceDown**: инстанс Scrapyd недоступен
- **ApiGatewayDown**: API Gateway недоступен
- **HighMemoryUsage**: высокое использование памяти
- **HighCPUUsage**: высокая загрузка CPU

## Запуск и настройка

Система мониторинга запускается вместе с основной системой через docker-compose:

```bash
docker-compose up -d
```

Для отдельного запуска только сервисов мониторинга:

```bash
./monitoring-setup.sh
```

### Использование переменных окружения

Учетные данные и другие конфиденциальные параметры хранятся в файле `.env`. Скрипт `monitoring-setup.sh` создаст этот файл из шаблона, если он не существует.

Файл `.env` используется для:
1. Хранения данных доступа для Telegram-бота (для оповещений)
2. Настроек Elasticsearch и других сервисов
3. Других конфиденциальных параметров

**Важно**: Никогда не коммитьте файл `.env` в репозиторий. Убедитесь, что он добавлен в `.gitignore`.

### Защита от спама уведомлений

Система включает защиту от дублирующихся уведомлений:

1. **Встроенная защита от спама**: Каждое уведомление записывается с временной меткой, и одинаковые уведомления игнорируются, если они отправляются слишком часто.

2. **Настройка интервала**: Вы можете настроить минимальный интервал между одинаковыми уведомлениями с помощью переменной `SPAM_PROTECTION_SECONDS` в файле `.env`.

3. **Стартовое уведомление**: При запуске системы отправляется только одно уведомление о запуске, независимо от количества контейнеров.

## Интеграция с пауками

Для сбора метрик из ваших пауков Scrapy добавьте `metrics_middleware.py` в ваш проект и включите его в настройках:

```python
# settings.py
SPIDER_MIDDLEWARES = {
    'your_project.middlewares.metrics_middleware.PrometheusMetricsMiddleware': 100,
}

# Дополнительные настройки для middleware
PROMETHEUS_MEMORY_CHECK_INTERVAL = 30  # секунды
```

## Устранение неполадок

### Elasticsearch не запускается

Возможная причина - недостаточно прав на директорию данных:

```bash
sudo chown -R 1000:1000 ./elasticsearch-data
```

### Filebeat не собирает логи

Проверьте права доступа к сокету Docker:

```bash
sudo chmod 666 /var/run/docker.sock
```

### Grafana не отображает данные

Убедитесь, что источники данных настроены правильно в Grafana UI. 