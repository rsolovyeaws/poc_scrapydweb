# Python CircleCI 2.1 configuration file
version: 2.1
orbs:
  codecov: codecov/codecov@1.0.2
  allure: ayte/allure@0.1.3
jobs:
  py39: &test-template
    docker:
      - image: cimg/python:3.9
    environment:
      SCRAPYDWEB_TESTMODE: True
    working_directory: ~/repo
    parameters:
      is-py27:
        type: boolean
        default: false
      use-scrapyd-v143:
        type: boolean
        default: false
      use-git:
        type: boolean
        default: false
      set-data-path:
        type: boolean
        default: false
      use-sqlite:
        type: boolean
        default: false
      use-postgresql:
        type: boolean
        default: false
      use-mysql:
        type: boolean
        default: false
      allure-version:
        description: Allure version to use
        type: string
        default: 2.13.1
      allure-configuration-path:
        description: Path to Allure configuration, uses default one if omitted
        type: string
        default: /usr/local/share/allure/config/allure.yml
      allure-target-path:
        description: Path for report directory
        type: string
        default: allure-report
      allure-results-path:
        description: Path to directory with test results
        type: string
        default: allure-results
      allure-artifact-path:
        description: Path that will be used when storing result as artifact
        type: string
        default: Report/Allure
    steps:
      - run:
          name: Install telnet
          command: |
            sudo apt-get update && sudo apt-get install telnet
      - run:
          name: Install Java 11
          command: |
            sudo apt-get update
            sudo apt-get install -y openjdk-11-jdk
      - run:
          name: Set JAVA_HOME
          command: |
            echo "export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64" >> $BASH_ENV
            source $BASH_ENV
      - run:
          name: Setup env
          command: |
            mkdir ~/logs
            ls -la ~
      - checkout
      - when:
          condition: <<parameters.is-py27>>
          steps:
            - run:
                name: Create virtual env in PY2
                command: |
                  virtualenv ./venv
      - unless:
          condition: <<parameters.is-py27>>
          steps:
            - run:
                name: Create virtual env in PY3
                command: |
                  python3 -m venv venv
      - when:
          condition: <<parameters.set-data-path>>
          steps:
            - run:
                name: Setup DATA_PATH
                command: |
                  echo $DATA_PATH
      - when:
          condition: <<parameters.use-sqlite>>
          steps:
            - run:
                name: Set DATABASE_URL to sqlite
                command: |
                  echo $DATABASE_URL
      - when:
          condition: <<parameters.use-postgresql>>
          steps:
            - run:
                name: Setup PSQL Databases
                command: |
                  # https://discuss.circleci.com/t/multiple-postgres-databases-in-circleci-2-0/23089
                  # createdb: could not connect to database template1: FATAL:  role "circleci" does not exist
                  # sudo apt install -y postgresql-client
                  # createdb -h localhost scrapydweb_apscheduler -O circleci
      - when:
          condition: <<parameters.use-mysql>>
          steps:
            - run:
                # mysql -h 127.0.0.1 -u root -prootpw -e "create database scrapydweb_apscheduler"
                name: Waiting for MySQL to be ready
                command: |
                  for i in `seq 1 10`;
                  do
                    nc -z 127.0.0.1 3306 && echo Success && exit 0
                    echo -n .
                    sleep 1
                  done
                  echo Failed waiting for MySQL && exit 1
            - run:
                name: Install MySQL CLI; Import dummy data; run an example query
                command: |
                  # sudo apt-get install default-mysql-client
                  # mysql -h 127.0.0.1 -u user -ppassw0rd test_db < sql-data/dummy.sql
                  # mysql -h 127.0.0.1 -u user -ppassw0rd --execute="SELECT * FROM test_db.Persons"
                  # https://discuss.circleci.com/t/how-can-i-create-multiple-mysql-databases-in-the-same-docker-image/24762
                  # mysql -h 127.0.0.1 -u root -prootpw -e "create database scrapydweb_apscheduler"
                  # mysql -h 127.0.0.1 -u root -prootpw -e "create database scrapydweb_timertasks"
                  # mysql -h 127.0.0.1 -u root -prootpw -e "create database scrapydweb_metadata"
                  # mysql -h 127.0.0.1 -u root -prootpw -e "create database scrapydweb_jobs"
      - run:
          name: Install dependencies
          command: |
            # python3 -m venv venv
            # virtualenv ./venv
            . venv/bin/activate
            which python
            python --version
            pip list
            pip install -r requirements.txt
            pip install -r requirements-tests.txt
            pip list
      - when:
          condition: <<parameters.use-git>>
          steps:
            - run:
                name: Git Scrapy, Scrapyd, and LogParser
                command: |
                  . venv/bin/activate
                  pip list
                  pip install -U git+https://github.com/scrapy/scrapy.git
                  pip install -U git+https://github.com/scrapy/scrapyd.git
                  pip install -U git+https://github.com/my8100/logparser.git
                  pip list
      - when:
          condition: <<parameters.use-scrapyd-v143>>
          steps:
            - run:
                name: scrapyd==1.4.3
                command: |
                  . venv/bin/activate
                  pip list
                  pip install scrapyd==1.4.3
                  pip list
      - run:
          name: Launch Scrapyd
          command: |
            pip list
            cd ~
            printf "[scrapyd]\nusername = admin\npassword = 12345\n" > scrapyd.conf
            cat scrapyd.conf
            nohup ~/repo/venv/bin/scrapyd > ~/scrapyd.log 2>&1 &
            sleep 5
            cat ~/scrapyd.log
            cd -
      - run:
          name: Run tests
          command: |
            pip list
            ls -la
            . venv/bin/activate
            flake8 . --count --exclude=./venv* --select=E9,F63,F7,F82 --show-source --statistics
            coverage erase
            # tests/test_schedule.py
            coverage run --source=scrapydweb -m pytest -s -vv -l --disable-warnings --alluredir=allure-results tests
      - run:
          name: Generate report
          command: |
            echo DATA_PATH: $DATA_PATH
            echo DATABASE_URL: $DATABASE_URL
            . venv/bin/activate
            coverage report
            coverage html
            coverage xml
            ls -la
            ls -la allure-results || echo 'ignore error'
            coveralls
          # https://discuss.circleci.com/t/make-custom-command-run-always-with-when-always/38957
          # https://circleci.com/docs/configuration-reference/#the-when-attribute
          when: always
      - store_artifacts:
          path: htmlcov
      - store_artifacts:
          path: coverage.xml
      - codecov/upload:
          file: coverage.xml
      # https://circleci.com/developer/orbs/orb/codecov/codecov
      # - codecov/upload
      # https://circleci.com/developer/orbs/orb/coveralls/coveralls
      # - coveralls/upload
      # https://discuss.circleci.com/t/how-can-we-publish-pytest-results-to-circleci-using-allure-reports/37830/2
      # https://circleci.com/developer/orbs/orb/ayte/allure
      # - allure/install
      # - allure/report
      # https://circleci.com/docs/configuration-reference/#the-when-step
      - when:
          condition:
            equal: [ 1, 1 ]
          steps:
            - run:
                name: Allure archive download
                command: >-
                  curl -L https://github.com/allure-framework/allure2/releases/download/<<
                  parameters.allure-version >>/allure-commandline-<< parameters.allure-version >>.zip -o
                  /tmp/allure.zip
                when: always
            - run:
                name: Archive extraction
                command: unzip /tmp/allure.zip
                when: always
            - run:
                name: Allure installation
                command: sudo mv allure-<< parameters.allure-version >> /usr/local/share/allure
                when: always
            - run:
                name: Allure binary symlinking
                command: sudo ln -s /usr/local/share/allure/bin/allure /usr/local/bin/allure
                when: always
      - when:
          condition:
            equal: [ 1, 1 ]
          steps:
            - run:
                name: >-
                  Allure report generation (<< parameters.allure-results-path >> -> <<
                  parameters.allure-target-path >>)
                command: |
                  allure generate \
                    --config << parameters.allure-configuration-path >> \
                    --report-dir << parameters.allure-target-path >> \
                    << parameters.allure-results-path >>
                when: always
            - store_artifacts:
                path: << parameters.allure-target-path >>
                destination: << parameters.allure-artifact-path >>
  py27:
    <<: *test-template
    docker:
      - image: cimg/python:2.7
  py36:
    <<: *test-template
    docker:
      - image: cimg/python:3.6
  py37:
    <<: *test-template
    docker:
      - image: cimg/python:3.7
  py38:
    <<: *test-template
    docker:
      - image: cimg/python:3.8
  py39-scrapyd-v143:
    <<: *test-template
    docker:
      - image: cimg/python:3.9
  py310-git-postgresql:
    <<: *test-template
    docker:
      - image: cimg/python:3.10
      # https://circleci.com/developer/images/image/cimg/postgres#image-tags
      - image: cimg/postgres:9.6
        environment:
          POSTGRES_USER: circleci
          # psycopg2.OperationalError: FATAL: database "circleci" does not exist
          # https://discuss.circleci.com/t/django-postgresql-and-circleci/15032
          POSTGRES_DB: circleci
          POSTGRES_PASSWORD: passw0rd
    environment:
      SCRAPYDWEB_TESTMODE: True
      DATABASE_URL: 'postgresql://circleci:fakepassword@localhost:5432'
  py310-git-mysql:
    <<: *test-template
    docker:
      - image: cimg/python:3.10
      # https://circleci.com/docs/2.0/postgres-config/#example-mysql-project
      # Plugin caching_sha2_password could not be loaded
      # - image: cimg/mysql:8.0.4
      # https://circleci.com/developer/images/image/cimg/mysql#image-tags
      - image: cimg/mysql:5.7
        environment:
          MYSQL_ROOT_PASSWORD: rootpw
          MYSQL_DATABASE: test_db
          MYSQL_USER: user
          MYSQL_PASSWORD: passw0rd
    environment:
      SCRAPYDWEB_TESTMODE: True
      DATABASE_URL: 'mysql://root:rootpw@127.0.0.1:3306'
  py310-sqlite:
    <<: *test-template
    docker:
      - image: cimg/python:3.10
    environment:
      SCRAPYDWEB_TESTMODE: True
      DATA_PATH: '/home/circleci/repo/scrapydweb_data'
      DATABASE_URL: 'sqlite:////home/circleci/repo/scrapydweb_database'
  py310-postgresql:
    <<: *test-template
    docker:
      - image: cimg/python:3.10
      - image: cimg/postgres:9.6
        environment:
          POSTGRES_USER: circleci
          # psycopg2.OperationalError: FATAL: database "circleci" does not exist
          # https://discuss.circleci.com/t/django-postgresql-and-circleci/15032
          POSTGRES_DB: circleci
          POSTGRES_PASSWORD: passw0rd
    environment:
      SCRAPYDWEB_TESTMODE: True
      DATABASE_URL: 'postgresql://circleci:fakepassword@localhost:5432'
  py310-mysql:
    <<: *test-template
    docker:
      - image: cimg/python:3.10
      # https://circleci.com/docs/2.0/postgres-config/#example-mysql-project
      # Plugin caching_sha2_password could not be loaded
      # - image: cimg/mysql:8.0.4
      - image: cimg/mysql:5.7
        environment:
          MYSQL_ROOT_PASSWORD: rootpw
          MYSQL_DATABASE: test_db
          MYSQL_USER: user
          MYSQL_PASSWORD: passw0rd
    environment:
      SCRAPYDWEB_TESTMODE: True
      DATABASE_URL: 'mysql://root:rootpw@127.0.0.1:3306'
  py311:
    <<: *test-template
    docker:
      - image: cimg/python:3.11
  py312:
    <<: *test-template
    docker:
      - image: cimg/python:3.12
  py312-scrapyd-v143:
    <<: *test-template
    docker:
      - image: cimg/python:3.12
  py313:
    <<: *test-template
    docker:
      - image: cimg/python:3.13
workflows:
  test:
    jobs:
      # - py27:
      #    is-py27: true
      # - py36
      # - py37
      - py38
      - py39
      - py39-scrapyd-v143:
          use-scrapyd-v143: true
      - py310-git-postgresql:
          use-git: true
          use-postgresql: true
      - py310-git-mysql:
          use-git: true
          use-mysql: true
      - py310-sqlite:
          set-data-path: true
          use-sqlite: true
      - py310-postgresql:
          use-postgresql: true
      - py310-mysql:
          use-mysql: true
      - py311
      - py312
      - py312-scrapyd-v143:
          use-scrapyd-v143: true
      - py313
